{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-13T14:32:18.872634Z","iopub.execute_input":"2023-11-13T14:32:18.872932Z","iopub.status.idle":"2023-11-13T14:32:28.308185Z","shell.execute_reply.started":"2023-11-13T14:32:18.872901Z","shell.execute_reply":"2023-11-13T14:32:28.307124Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/input/tunes-data/data.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nimport warnings\nwarnings.filterwarnings('ignore')\ndef split_text_into_characters(file_path):\n    with open(file_path, 'r') as file:\n        text = file.read()\n        characters = list(text)  # Splitting the text into individual characters\n\n    return characters\npath='/kaggle/input/tunes-data/data.txt'\ntokens=split_text_into_characters(path)\nprint(len(tokens))\nvocab=pd.Series(tokens).unique()\nprint(vocab.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-13T14:33:19.686171Z","iopub.execute_input":"2023-11-13T14:33:19.687371Z","iopub.status.idle":"2023-11-13T14:33:19.785367Z","shell.execute_reply.started":"2023-11-13T14:33:19.687324Z","shell.execute_reply":"2023-11-13T14:33:19.784269Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"452328\n(93,)\n","output_type":"stream"}]},{"cell_type":"code","source":"vocab","metadata":{"execution":{"iopub.status.busy":"2023-11-13T14:33:22.676069Z","iopub.execute_input":"2023-11-13T14:33:22.677006Z","iopub.status.idle":"2023-11-13T14:33:22.684113Z","shell.execute_reply.started":"2023-11-13T14:33:22.676973Z","shell.execute_reply":"2023-11-13T14:33:22.683032Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"array(['\\n', 'X', ':', '1', 'T', 'A', ' ', 'a', 'n', 'd', \"'\", 's', 'W',\n       'l', 't', 'z', '%', 'N', 'o', 'i', 'g', 'h', 'm', 'M', 'u', 'c',\n       'D', 'b', 'e', 'S', 'k', 'P', '3', '/', '4', 'L', 'K', 'G', '|',\n       '\"', '2', 'B', '[', ']', 'F', '=', 'C', 'f', 'r', 'y', 'v', '(',\n       'E', '\\\\', '^', '#', '6', '8', 'p', 'H', '5', 'R', '7', '_', '9',\n       '0', 'J', ')', 'I', 'j', '-', '~', 'w', 'O', '&', ',', '.', 'Y',\n       '?', 'V', 'x', '+', 'q', '!', '>', 'Q', 'U', '*', '@', '<', '{',\n       '}', 'Z'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"char_to_idx={}\nfor i in range(vocab.shape[0]):\n    char_to_idx[vocab[i]]=i\ntokens=pd.Series(tokens).map(char_to_idx)\ntokens","metadata":{"execution":{"iopub.status.busy":"2023-11-13T14:33:24.389743Z","iopub.execute_input":"2023-11-13T14:33:24.390683Z","iopub.status.idle":"2023-11-13T14:33:24.462703Z","shell.execute_reply.started":"2023-11-13T14:33:24.390640Z","shell.execute_reply":"2023-11-13T14:33:24.461685Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"0          0\n1          1\n2          2\n3          3\n4          0\n          ..\n452323    38\n452324    38\n452325     0\n452326     0\n452327     0\nLength: 452328, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"def create_batches(data,batch_size,seq_len,vocab):\n    n=len(data)\n    batch_count=n//(batch_size*seq_len)\n    X=[]\n    for i in range(batch_count):\n        x_batch=[]\n        idx=i*seq_len\n        for row in range(batch_size):\n            x_temp=[]\n            for j in range(seq_len):\n                x_temp.append(data[idx+j])\n            x_batch.append(x_temp)\n            idx+=(seq_len*batch_count)\n#             print(i,row,idx)\n        X.append(x_batch)\n    \n    return X\n\nseq_len=256\nbatch_size=128\nreal_data=create_batches(tokens,len(tokens)//seq_len,seq_len,vocab)\nreal_data=np.array(real_data)\nreal_data=real_data.reshape((1766,256))\nreal_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-13T14:33:53.400048Z","iopub.execute_input":"2023-11-13T14:33:53.400972Z","iopub.status.idle":"2023-11-13T14:33:55.713014Z","shell.execute_reply.started":"2023-11-13T14:33:53.400928Z","shell.execute_reply":"2023-11-13T14:33:55.712023Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(1766, 256)"},"metadata":{}}]},{"cell_type":"code","source":"# import numpy as np\n# from keras.models import Sequential\n# from keras.layers import Dense, LSTM , Input\n\n# # Generator architecture\n# num_chars=vocab.shape[0]\n# generator = Sequential()\n# generator.add(LSTM(128, input_shape=(seq_length, num_chars)))\n# generator.add(Dense(num_chars, activation='softmax'))\n# generator.compile(loss='categorical_crossentropy', optimizer='adam')\n\n# # Discriminator architecture\n# discriminator = Sequential()\n# discriminator.add(LSTM(128, input_shape=(seq_length, num_chars)))\n# discriminator.add(Dense(1, activation='sigmoid'))\n# discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n\n# # Combined GAN model\n# discriminator.trainable = False\n# gan_input = Input(shape=(seq_length, num_chars))\n# generated_sequence = generator(gan_input)\n# gan_output = discriminator(generated_sequence)\n# gan = Model(gan_input, gan_output)\n# gan.compile(loss='binary_crossentropy', optimizer='adam')\n\n# # Training loop\n# for epoch in range(num_epochs):\n#     # Generate a batch of real sequences\n#     real_sequences = real_data\n\n#     # Generate a batch of random noise vectors\n#     noise = np.random.normal(0, 1, size=(batch_size, seq_length, num_chars))\n\n#     # Generate a batch of fake sequences using the generator\n#     generated_sequences = generator.predict(noise)\n\n#     # Train the discriminator on real and fake sequences\n#     discriminator_loss_real = discriminator.train_on_batch(real_sequences, np.ones((batch_size, 1)))\n#     discriminator_loss_fake = discriminator.train_on_batch(generated_sequences, np.zeros((batch_size, 1)))\n#     discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n\n#     # Train the generator to fool the discriminator\n#     gan_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n\n#     # Print the losses for monitoring\n#     print(f\"Epoch: {epoch+1}/{num_epochs}, Discriminator Loss: {discriminator_loss}, GAN Loss: {gan_loss}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T18:03:12.334561Z","iopub.execute_input":"2023-10-02T18:03:12.335186Z","iopub.status.idle":"2023-10-02T18:03:12.340645Z","shell.execute_reply.started":"2023-10-02T18:03:12.335148Z","shell.execute_reply":"2023-10-02T18:03:12.339759Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"# import tensorflow as tf\n# from tensorflow.keras import layers\n\n# latent_dim = 100  # Size of the random noise input vector\n# sequence_length = seq_len  # Length of input sequence\n\n# # Generator architecture\n# generator = tf.keras.Sequential()\n# generator.add(layers.Reshape((1, latent_dim), input_shape=(latent_dim,)))\n# generator.add(layers.LSTM(256, input_shape=(latent_dim,), return_sequences=True))\n# generator.add(layers.BatchNormalization())\n# generator.add(layers.LSTM(512, return_sequences=True))\n# generator.add(layers.BatchNormalization())\n# generator.add(layers.TimeDistributed(layers.Dense(128, activation='relu')))\n# generator.add(layers.BatchNormalization())\n# generator.add(layers.TimeDistributed(layers.Dense(1, activation='sigmoid')))\n# generator.build(input_shape=(None, latent_dim))\n# generator.summary()\n# # Discriminator architecture\n# discriminator = tf.keras.Sequential()\n# discriminator.add(layers.LSTM(512, input_shape=(sequence_length, 1), return_sequences=True))\n# discriminator.add(layers.BatchNormalization())\n# discriminator.add(layers.LSTM(256, return_sequences=True))\n# discriminator.add(layers.BatchNormalization())\n# discriminator.add(layers.TimeDistributed(layers.Dense(128, activation='relu')))\n# discriminator.add(layers.BatchNormalization())\n# discriminator.add(layers.TimeDistributed(layers.Dense(1, activation='sigmoid')))\n# discriminator.build(input_shape=(None, sequence_length, 1))\n# discriminator.summary()\n# # Combined GAN model\n# gan = tf.keras.Sequential([generator, discriminator])\n# gan.build(input_shape=(None, latent_dim))\n\n# # Rest of the code (compilation, training loop, etc.)\n# gan.summary()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T18:03:12.342137Z","iopub.execute_input":"2023-10-02T18:03:12.342752Z","iopub.status.idle":"2023-10-02T18:03:14.651028Z","shell.execute_reply.started":"2023-10-02T18:03:12.342720Z","shell.execute_reply":"2023-10-02T18:03:14.650038Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Model: \"sequential_34\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n reshape_5 (Reshape)         (None, 1, 100)            0         \n                                                                 \n lstm_44 (LSTM)              (None, 1, 256)            365568    \n                                                                 \n batch_normalization_27 (Bat  (None, 1, 256)           1024      \n chNormalization)                                                \n                                                                 \n lstm_45 (LSTM)              (None, 1, 512)            1574912   \n                                                                 \n batch_normalization_28 (Bat  (None, 1, 512)           2048      \n chNormalization)                                                \n                                                                 \n time_distributed_18 (TimeDi  (None, 1, 128)           65664     \n stributed)                                                      \n                                                                 \n batch_normalization_29 (Bat  (None, 1, 128)           512       \n chNormalization)                                                \n                                                                 \n time_distributed_19 (TimeDi  (None, 1, 1)             129       \n stributed)                                                      \n                                                                 \n=================================================================\nTotal params: 2,009,857\nTrainable params: 2,008,065\nNon-trainable params: 1,792\n_________________________________________________________________\nModel: \"sequential_35\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n lstm_46 (LSTM)              (None, 256, 512)          1052672   \n                                                                 \n batch_normalization_30 (Bat  (None, 256, 512)         2048      \n chNormalization)                                                \n                                                                 \n lstm_47 (LSTM)              (None, 256, 256)          787456    \n                                                                 \n batch_normalization_31 (Bat  (None, 256, 256)         1024      \n chNormalization)                                                \n                                                                 \n time_distributed_20 (TimeDi  (None, 256, 128)         32896     \n stributed)                                                      \n                                                                 \n batch_normalization_32 (Bat  (None, 256, 128)         512       \n chNormalization)                                                \n                                                                 \n time_distributed_21 (TimeDi  (None, 256, 1)           129       \n stributed)                                                      \n                                                                 \n=================================================================\nTotal params: 1,876,737\nTrainable params: 1,874,945\nNon-trainable params: 1,792\n_________________________________________________________________\nModel: \"sequential_36\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n sequential_34 (Sequential)  (None, 1, 1)              2009857   \n                                                                 \n sequential_35 (Sequential)  (None, 256, 1)            1876737   \n                                                                 \n=================================================================\nTotal params: 3,886,594\nTrainable params: 3,883,010\nNon-trainable params: 3,584\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_g():\n    model=keras.models.Sequential()\n    model.add(keras.layers.Dense(64))\n    model.add(keras.layers.LeakyReLU(0.2))\n    model.add(keras.layers.Dropout(0.3))\n    model.add(keras.layers.Dense(128))\n    model.add(keras.layers.LeakyReLU(0.2))\n    model.add(keras.layers.Dropout(0.3))\n    model.add(keras.layers.Dense(vocab.shape[0],activation='tanh'))\n#     model.summary()\n    model.compile(optimizer='adam',loss=keras.losses.binary_crossentropy)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-11-13T14:41:14.794674Z","iopub.execute_input":"2023-11-13T14:41:14.795441Z","iopub.status.idle":"2023-11-13T14:41:14.802508Z","shell.execute_reply.started":"2023-11-13T14:41:14.795406Z","shell.execute_reply":"2023-11-13T14:41:14.801273Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def create_d():\n    model=keras.models.Sequential()\n    model.add(keras.layers.Embedding(input_dim=vocab.shape[0],output_dim=512,input_length=seq_len))\n    for i in range(3):\n        model.add(keras.layers.LSTM(128,return_sequences=(i!=2)))\n    model.add(keras.layers.Dense(1,activation='sigmoid'))\n#     model.summary()\n    model.compile(optimizer='adam',loss=keras.losses.binary_crossentropy)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-11-13T14:41:16.215995Z","iopub.execute_input":"2023-11-13T14:41:16.216758Z","iopub.status.idle":"2023-11-13T14:41:16.223466Z","shell.execute_reply.started":"2023-11-13T14:41:16.216727Z","shell.execute_reply":"2023-11-13T14:41:16.222373Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Layer\n\nclass OneHotToIndex(Layer):\n    def __init__(self):\n        super(OneHotToIndex, self).__init__()\n\n    def call(self, inputs):\n        return tf.argmax(inputs, axis=-1)","metadata":{"execution":{"iopub.status.busy":"2023-11-13T14:41:23.085991Z","iopub.execute_input":"2023-11-13T14:41:23.086707Z","iopub.status.idle":"2023-11-13T14:41:23.091924Z","shell.execute_reply.started":"2023-11-13T14:41:23.086677Z","shell.execute_reply":"2023-11-13T14:41:23.090919Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def create_gan(g,d):\n    d.trainable=False\n    inp=keras.layers.Input(shape=seq_len)\n    x=g(inp)\n#     x=OneHotToIndex()(x)\n    out=d(x)\n    model=keras.Model(inputs=inp,outputs=out)\n    model.summary()\n    model.compile(optimizer=keras.optimizers.Adam(0.0002,0.5),loss=keras.losses.binary_crossentropy)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-11-13T14:41:56.778770Z","iopub.execute_input":"2023-11-13T14:41:56.779141Z","iopub.status.idle":"2023-11-13T14:41:56.785327Z","shell.execute_reply.started":"2023-11-13T14:41:56.779110Z","shell.execute_reply":"2023-11-13T14:41:56.784289Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"create_gan(create_g(),create_d())","metadata":{"execution":{"iopub.status.busy":"2023-11-13T14:41:57.862540Z","iopub.execute_input":"2023-11-13T14:41:57.863425Z","iopub.status.idle":"2023-11-13T14:41:59.368155Z","shell.execute_reply.started":"2023-11-13T14:41:57.863388Z","shell.execute_reply":"2023-11-13T14:41:59.367087Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Model: \"model_3\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_5 (InputLayer)        [(None, 256)]             0         \n                                                                 \n sequential_8 (Sequential)   (None, 93)                36765     \n                                                                 \n sequential_9 (Sequential)   (None, 1)                 639105    \n                                                                 \n=================================================================\nTotal params: 675,870\nTrainable params: 36,765\nNon-trainable params: 639,105\n_________________________________________________________________\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"<keras.engine.functional.Functional at 0x7b2ea444c160>"},"metadata":{}}]},{"cell_type":"code","source":"def view_music(g):\n    noise=np.random.normal(0,vocab.shape[0],size=(batch_size,seq_len))\n    gen_data=g.predict(noise)\n    data=OhetoInd(gen_data)\n    notes=3\n    for i in range(notes):\n        music=[vocab[j] for j in data[i]]\n        output='a'\n        for v in music:\n            output+=v\n        print(output)\n        print('--------------------------')","metadata":{"execution":{"iopub.status.busy":"2023-11-13T14:35:48.358104Z","iopub.execute_input":"2023-11-13T14:35:48.359063Z","iopub.status.idle":"2023-11-13T14:35:48.366355Z","shell.execute_reply.started":"2023-11-13T14:35:48.359022Z","shell.execute_reply":"2023-11-13T14:35:48.365420Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def OhetoInd(data):\n    music=[]\n    for i in range(data.shape[0]):\n        temp=[]\n        for j in range(data.shape[1]):\n            temp.append(np.argmax(data[i][j]))\n        music.append(temp)\n    return music","metadata":{"execution":{"iopub.status.busy":"2023-11-13T14:35:22.124713Z","iopub.execute_input":"2023-11-13T14:35:22.125481Z","iopub.status.idle":"2023-11-13T14:35:22.130728Z","shell.execute_reply.started":"2023-11-13T14:35:22.125450Z","shell.execute_reply":"2023-11-13T14:35:22.129647Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"epochs=100\nbatch_size=64\ndata=real_data\ng=create_g()\nd=create_d()\ngan=create_gan(g,d)\n    \nfor e in range(1,epochs+1):\n    noise=np.random.randint(0,vocab.shape[0],size=(batch_size,seq_len))\n    gen_data=g.predict(noise)\n    gen_data\n    gen_data=OhetoInd(gen_data)\n\n    if e==1 or e%100==0:\n        view_music(g)\ntraining(100,64,real_data)","metadata":{"execution":{"iopub.status.busy":"2023-11-13T14:42:03.185920Z","iopub.execute_input":"2023-11-13T14:42:03.186764Z","iopub.status.idle":"2023-11-13T14:42:09.433889Z","shell.execute_reply.started":"2023-11-13T14:42:03.186729Z","shell.execute_reply":"2023-11-13T14:42:09.432597Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Model: \"model_4\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_6 (InputLayer)        [(None, 256)]             0         \n                                                                 \n sequential_10 (Sequential)  (None, 93)                36765     \n                                                                 \n sequential_11 (Sequential)  (None, 1)                 639105    \n                                                                 \n=================================================================\nTotal params: 675,870\nTrainable params: 36,765\nNon-trainable params: 639,105\n_________________________________________________________________\n2/2 [==============================] - 0s 2ms/step\n2/2 [==============================] - 0s 3ms/step\na\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n--------------------------\na\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n--------------------------\na\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n--------------------------\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 2ms/step\n2/2 [==============================] - 0s 2ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 2ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 2ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 2ms/step\n2/2 [==============================] - 0s 2ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 2ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 2ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 2ms/step\n2/2 [==============================] - 0s 2ms/step\n2/2 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 3ms/step\n1/2 [==============>...............] - ETA: 0s","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[26], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      9\u001b[0m     noise\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m,vocab\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],size\u001b[38;5;241m=\u001b[39m(batch_size,seq_len))\n\u001b[0;32m---> 10\u001b[0m     gen_data\u001b[38;5;241m=\u001b[39m\u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     gen_data\n\u001b[1;32m     12\u001b[0m     gen_data\u001b[38;5;241m=\u001b[39mOhetoInd(gen_data)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:2403\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2394\u001b[0m                 tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure_up_to(\n\u001b[1;32m   2395\u001b[0m                     batch_outputs,\n\u001b[1;32m   2396\u001b[0m                     \u001b[38;5;28;01mlambda\u001b[39;00m output, batch_output: output\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2400\u001b[0m                     batch_outputs,\n\u001b[1;32m   2401\u001b[0m                 )\n\u001b[1;32m   2402\u001b[0m             end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 2403\u001b[0m             \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_predict_batch_end\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2404\u001b[0m \u001b[43m                \u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_outputs\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m   2405\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected result of `predict_function` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2409\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Empty batch_outputs). Please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2413\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124missue/bug to `tf.keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2414\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/callbacks.py:519\u001b[0m, in \u001b[0;36mCallbackList.on_predict_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_predict_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    513\u001b[0m \n\u001b[1;32m    514\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_predict_batch_hooks:\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPREDICT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    327\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 345\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    348\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    392\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 393\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/callbacks.py:1101\u001b[0m, in \u001b[0;36mProgbarLogger.on_predict_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_predict_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;66;03m# Don't pass prediction results.\u001b[39;00m\n\u001b[0;32m-> 1101\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/callbacks.py:1170\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m   1169\u001b[0m     logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m-> 1170\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/generic_utils.py:296\u001b[0m, in \u001b[0;36mProgbar.update\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    293\u001b[0m         info \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m info\n\u001b[0;32m--> 296\u001b[0m     \u001b[43mio_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline_break\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/io_utils.py:80\u001b[0m, in \u001b[0;36mprint_msg\u001b[0;34m(message, line_break)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(message)\n\u001b[0;32m---> 80\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(message)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py:500\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(evt\u001b[38;5;241m.\u001b[39mset)\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;66;03m# and give a timeout to avoid\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mevt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush_timeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    501\u001b[0m         \u001b[38;5;66;03m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[1;32m    502\u001b[0m         \u001b[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIOStream.flush timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39m__stderr__)\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n","File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"real_data=data[np.random.randint(0,data.shape[0],size=batch_size)]\ntrain=np.concatenate([real_data,gen_data])\ntrain,train.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-02T18:09:37.844589Z","iopub.execute_input":"2023-10-02T18:09:37.845023Z","iopub.status.idle":"2023-10-02T18:09:37.888743Z","shell.execute_reply.started":"2023-10-02T18:09:37.844974Z","shell.execute_reply":"2023-10-02T18:09:37.887553Z"},"trusted":true},"execution_count":75,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[75], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m real_data\u001b[38;5;241m=\u001b[39mdata[np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m,data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],size\u001b[38;5;241m=\u001b[39mbatch_size)]\n\u001b[0;32m----> 2\u001b[0m train\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mreal_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgen_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m train,train\u001b[38;5;241m.\u001b[39mshape\n","File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 256 and the array at index 1 has size 93"],"ename":"ValueError","evalue":"all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 256 and the array at index 1 has size 93","output_type":"error"}]},{"cell_type":"code","source":"labels=np.zeros(2*batch_size)\nlabels[:batch_size]=0.9\nd.trainable=True\nd.fit(train,labels)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T18:09:43.004849Z","iopub.execute_input":"2023-10-02T18:09:43.005184Z","iopub.status.idle":"2023-10-02T18:09:43.039730Z","shell.execute_reply.started":"2023-10-02T18:09:43.005158Z","shell.execute_reply":"2023-10-02T18:09:43.038548Z"},"trusted":true},"execution_count":76,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[76], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m labels[:batch_size]\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m\n\u001b[1;32m      3\u001b[0m d\u001b[38;5;241m.\u001b[39mtrainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m d\u001b[38;5;241m.\u001b[39mfit(\u001b[43mtrain\u001b[49m,labels)\n","\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"],"ename":"NameError","evalue":"name 'train' is not defined","output_type":"error"}]},{"cell_type":"code","source":"noise=np.random.randint(0,vocab.shape[0],size=(batch_size,seq_len))\ny=np.ones(batch_size)\nd.trainable=False\ngan.fit(noise,y)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T18:09:43.985251Z","iopub.execute_input":"2023-10-02T18:09:43.985620Z","iopub.status.idle":"2023-10-02T18:09:44.148721Z","shell.execute_reply.started":"2023-10-02T18:09:43.985591Z","shell.execute_reply":"2023-10-02T18:09:44.147401Z"},"trusted":true},"execution_count":77,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[77], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m y\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mones(batch_size)\n\u001b[1;32m      3\u001b[0m d\u001b[38;5;241m.\u001b[39mtrainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mgan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/tmp/__autograph_generated_fileb2gr6zcr.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_8' (type Functional).\n    \n    Input 0 of layer \"sequential_40\" is incompatible with the layer: expected shape=(None, 256), found shape=(32, 93)\n    \n    Call arguments received by layer 'model_8' (type Functional):\n       inputs=tf.Tensor(shape=(32, 256), dtype=int64)\n       training=True\n       mask=None\n"],"ename":"ValueError","evalue":"in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_8' (type Functional).\n    \n    Input 0 of layer \"sequential_40\" is incompatible with the layer: expected shape=(None, 256), found shape=(32, 93)\n    \n    Call arguments received by layer 'model_8' (type Functional):\n       inputs=tf.Tensor(shape=(32, 256), dtype=int64)\n       training=True\n       mask=None\n","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}